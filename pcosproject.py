# -*- coding: utf-8 -*-
"""pcosproject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-1Yem-AvcWMOrDAijwcj-etvxkjPEGqw
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/data without infertility _final.csv')

df.shape

df.head()

df = df.dropna(how='all')
df.shape

df.info()

df.isnull().sum()

df.duplicated().sum()

sns.countplot(x='PCOS (Y/N)', data=df)
plt.show()
df['PCOS (Y/N)'].value_counts()

numericalcols = ['PCOS (Y/N)']
for col in numericalcols:
    sns.histplot(df[col], kde=True)
    plt.title(col)
    plt.show()

plt.hist(df['BMI'], bins=20 , edgecolor='black')
plt.xlabel('BMI')
plt.ylabel('Frequency')
plt.show()

sns.boxplot(x='PCOS (Y/N)', y='Cycle length(days)', data=df)
plt.show()

plt.hist(df['Cycle length(days)'], bins=20 , edgecolor='black')
plt.xlabel('Cycle length(days)')
plt.ylabel('Frequency')
plt.show()

sns.boxplot(data=df, y='AMH(ng/mL)')

sns.boxplot(data=df, y='FSH/LH', x = 'PCOS (Y/N)')

plt.hist(df['Reg.Exercise(Y/N)'], bins=20 , edgecolor='cyan')
plt.xlabel('Reg.Exercise(Y/N)')
plt.ylabel('Frequency')
plt.show()

print(df.columns.tolist())

df['Fast food (Y/N)'] = df['Fast food (Y/N)'].fillna(df['Fast food (Y/N)'].mode()[0])
df['Marraige Status (Yrs)'] = df['Marraige Status (Yrs)'].fillna(df['Marraige Status (Yrs)'].mode()[0])

print(df[['Fast food (Y/N)', 'Marraige Status (Yrs)']].isnull().sum())

np.set_printoptions(suppress=True)  # No scientific notation

numerical_features = ['Weight gain(Y/N)', 'hair growth(Y/N)', 'Skin darkening (Y/N)','Sl. No', 'Patient File No.']

for col in df.columns:
    if col not in numerical_features:
        print(f"\nColumn: {col}")  # Explicitly print the column name
        print(df[col].unique())     # Show unique values
        print("-" * 50)

df = df.drop(columns=['Sl. No', 'Patient File No.'])

for col in df.select_dtypes(include='number').columns:
    df[col] = df[col].fillna(df[col].median())

df['AMH(ng/mL)'] = pd.to_numeric(df['AMH(ng/mL)'], errors='coerce')
df['II    beta-HCG(mIU/mL)'] = pd.to_numeric(df['II    beta-HCG(mIU/mL)'], errors='coerce')

import pandas as pd
columns = [' Age (yrs)', 'Weight (Kg)', 'Height(Cm) ', 'BMI', 'Pulse rate(bpm) ', 'RR (breaths/min)',
           'Hb(g/dl)', 'Cycle(R/I)', 'Cycle length(days)', 'Marraige Status (Yrs)',
           'No. of aborptions', 'FSH(mIU/mL)', 'LH(mIU/mL)', 'FSH/LH', 'Hip(inch)',
           'Waist(inch)', 'Waist:Hip Ratio', 'TSH (mIU/L)', 'AMH(ng/mL)', 'PRL(ng/mL)',
           'PRG(ng/mL)', 'RBS(mg/dl)', 'Follicle No. (L)', 'Follicle No. (R)',
           '  I   beta-HCG(mIU/mL)', 'II    beta-HCG(mIU/mL)']
# Option 1: Remove rows with outliers in any of the selected columns
def remove_outliers_iqr(df, columns):
    for col in columns:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower = Q1 - 1.5 * IQR
        upper = Q3 + 1.5 * IQR
        df = df[(df[col] >= lower) & (df[col] <= upper)]
    return df

df_no_outliers = remove_outliers_iqr(df.copy(), columns)
# Option 2: Cap outliers for all specified columns
def cap_outliers_iqr(df, columns):
    for col in columns:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower = Q1 - 1.5 * IQR
        upper = Q3 + 1.5 * IQR
        df[col] = df[col].clip(lower=lower, upper=upper)
    return df
df_capped = cap_outliers_iqr(df.copy(), columns)
# Display result
print("DataFrame with rows removed for outliers:\n", df_no_outliers.head())
print("DataFrame with capped outliers:\n", df_capped.head())

print(df['Cycle(R/I)'].unique())

df['Cycle(R/I)'].value_counts()

df['Blood Group'].value_counts()

# Convert object columns to numeric
df["AMH(ng/mL)"] = pd.to_numeric(df["AMH(ng/mL)"], errors='coerce')
df["II    beta-HCG(mIU/mL)"] = pd.to_numeric(df["II    beta-HCG(mIU/mL)"], errors='coerce')
#it introduce the nan value to  it

df.drop_duplicates(inplace=True)

X = df_capped.drop('PCOS (Y/N)', axis=1)
y = df_capped['PCOS (Y/N)']

from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='mean')
X_imputed_array = imputer.fit_transform(X)
X_cleaned = pd.DataFrame(X_imputed_array, columns=X.columns, index=X.index)

from sklearn.preprocessing import RobustScaler

scaler = RobustScaler()
X_scaled_array = scaler.fit_transform(X_cleaned)
X_final = pd.DataFrame(X_scaled_array, columns=X_cleaned.columns, index=X_cleaned.index)

X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42, stratify=y)

X_train.shape

smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

plt.figure(figsize=(15, 15))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation heatmap")
plt.show()

"""idk did we need to do heatmap"""

from sklearn.linear_model import LogisticRegression

model = LogisticRegression(max_iter=1000)
model.fit(X_train_resampled, y_train_resampled)

y_pred = model.predict(X_test)

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n" , confusion_matrix(y_test, y_pred))
print("Classification Report:\n" , classification_report(y_test, y_pred))

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred)

# Create a heatmap
plt.figure(figsize=(5, 3))
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=['No PCOS', 'PCOS'], yticklabels=['No PCOS', 'PCOS'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

models = {
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42),
    "XGBoost": XGBClassifier(random_state=42)
}

cv = {}
for model_name, model in models.items():
    cv[model_name] = cross_val_score(model, X_train_resampled, y_train_resampled, cv=5, scoring='accuracy')
    print(f"{model_name} CV Accuracy: {cv[model_name].mean():.4f}")

# Initializing models
decision_tree = DecisionTreeClassifier(random_state=42)
random_forest = RandomForestClassifier(random_state=42)
xgboost_classifier = XGBClassifier(random_state=42)

param_grid_dt = {
    "criterion": ["gini", "entropy"],
    "max_depth": [None, 10, 20, 30, 50, 70],
    "min_samples_split": [2, 5, 10],
    "min_samples_leaf": [1, 2, 4]
}


param_grid_rf = {
    "n_estimators": [50, 100, 200, 500],
    "max_depth": [None, 10, 20, 30],
    "min_samples_split": [2, 5, 10],
    "min_samples_leaf": [1, 2, 4],
    "bootstrap": [True, False]
}


param_grid_xgb = {
    "n_estimators": [50, 100, 200, 500],
    "max_depth": [3, 5, 7, 10],
    "learning_rate": [0.01, 0.1, 0.2, 0.3],
    "subsample": [0.5, 0.7, 1.0],
    "colsample_bytree": [0.5, 0.7, 1.0]
}

random_search_dt = RandomizedSearchCV(estimator=decision_tree, param_distributions=param_grid_dt, n_iter=20, cv=5, scoring="accuracy", random_state=42)
random_search_rf = RandomizedSearchCV(estimator=random_forest, param_distributions=param_grid_rf, n_iter=20, cv=5, scoring="accuracy", random_state=42)
random_search_xgb = RandomizedSearchCV(estimator=xgboost_classifier, param_distributions=param_grid_xgb, n_iter=20, cv=5, scoring="accuracy", random_state=42)

random_search_dt.fit(X_train_resampled, y_train_resampled)
random_search_rf.fit(X_train_resampled, y_train_resampled)
random_search_xgb.fit(X_train_resampled, y_train_resampled)

random_search_dt.best_estimator_

random_search_dt.best_score_

random_search_rf.best_estimator_

random_search_rf.best_score_

random_search_xgb.best_estimator_

random_search_xgb.best_score_

# Get the model with best score

best_model = None
best_score = 0

#best_model: will hold the best-performing model
#best_score: starts with 0 and will be updated with the highest score


if random_search_dt.best_score_ > best_score:
  best_model = random_search_dt.best_estimator_
  best_score = random_search_dt.best_score_

if random_search_rf.best_score_ > best_score:
  best_model = random_search_rf.best_estimator_
  best_score = random_search_rf.best_score_

if random_search_xgb.best_score_ > best_score:
  best_model = random_search_xgb.best_estimator_
  best_score = random_search_xgb.best_score_


#random_search_dt.best_score_ (0.85) > best_score (0):
#Yes → Set best_model = random_search_dt.best_estimator_, best_score = 0.85
#random_search_rf.best_score_ (0.919) > best_score (0.85):
#Yes → Set best_model = random_search_rf.best_estimator_, best_score = 0.919
#random_search_xgb.best_score_ (0.90) > best_score (0.919):
#No: Set best_model = random_search_rf.best_estimator_, best_score = 0.919

print(f'Best Model: {best_model}')
print(f'Best Score: {best_score:.2f}')

y_test_pred = best_model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_test_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_test_pred))
print("Classification Report:\n", classification_report(y_test, y_test_pred))

cm1 = confusion_matrix(y_test, y_test_pred)
plt.figure(figsize=(5, 3))
sns.heatmap(cm1, annot=True, fmt='d', cmap='Blues', xticklabels=['No PCOS', 'PCOS'], yticklabels=['No PCOS', 'PCOS'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

